基于bert预训练模型对imdb模型数据集进行情感分析

实验步骤：

# 1、模型
选择3-4个预训练模型(暂定为google的bert系列)
- [base-uncased](https://huggingface.co/google-bert/bert-base-uncased)
- [large-uncased](https://huggingface.co/google-bert/bert-large-uncased)
- [base-multilingual-uncased](https://huggingface.co/google-bert/bert-base-multilingual-uncased)

# 2、预训练模型的推理
如果算力足够，则用上述预训练模型对完整的数据集进行情感分析，否则取10%（**训练集和测试集均是如此**）进行推理.

可参考的思路：
```python
"""从训练集中读取数据""" 
import pandas as pd
# 用pandas读取.parquet的数据
df = pd.read_parquet("/path/to/parquet")
selected_columns = df[['text', 'label']]
result = selected_columns.values.tolist()
print(result[24999])
#['The story ...McKenzie(Barry Crocker) are highlights.', 1]

''' 将训练集中text部分作为BERT的输入，得到output'''
from transformers import BertTokenizer, BertModel
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')
model = BertModel.from_pretrained("bert-base-multilingual-uncased")
text = result[24999] # 此处应对每个元素进行计算
encoded_input = tokenizer(text, return_tensors='pt')
output = model(**encoded_input)
# 此处的output含last_hidden_state,pooler_output两个部分，时间充裕的话可以考虑分别使用两个进行分析（没时间的话选择last_hidden_state即可）

'''保存训练数据'''


'''构建逻辑回归分类器，训练数据为output，label'''


'''用上述训练的逻辑回归分类器对测试集数据进行推理，与上述操作类似'''


''' 上一步骤中应记录判断错误的段落序号，找出3个预训练模型不完全判断错误的段落'''



'''可视化，考虑将段落放置在一个二维图中，每个单词占据一个小格子，格子的背景颜色随着注意力的强度变化（具体如何计算注意力强度我没有了解过，可以问问GPT然后量力而行）'''
```

remark：
- 这里仅训练自己搭建的逻辑回归分类器，预训练模型不参与训练
- 可以考虑将output_token以及相应的0/1构成的数据保存为文件，
- 错误样本选取3个左右，也可以自行增减

# 3、预训练模型的微调


基于训练集进行训练，1-3个epoch，选取效果最好的epoch的checkpoint再次在测试集（与步骤2的数据一致）上进行推理，并分析与之前的区别

remark：
- 此步骤仅分析准确率，不针对个例进行分析

# 报告中应呈现的数据

3个预训练模型训练出的分类器在测试集上的准确率

对预训练模型判断错误的样本进行分析（可视化，或者仅罗列一下）

微调后的模型训练出的分类器在测试集上的准确率（包括每个checkpoint的数据）






